{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab3929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde4ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordBagOfAuthorClassifier:\n",
    "    __unnecessary_chars = [\"!\",\",\",\".\",\"    \",\":\",\";\",\"?\",\"(\",\")\",\"—\",\"*\",\"»\",\"…\",\"«\",\"—\",\"-\",\"„\",\"”\",'\"',\"°\",\"'\"] \n",
    "    __stops = ['a', 'aby', 'ach', 'acz', 'aczkolwiek', 'aj', 'albo', 'ale', 'alez', 'ależ', 'ani', 'az', 'aż', 'bardziej', 'bardzo', 'beda', 'bedzie', 'bez', 'deda', 'będą', 'bede', 'będę', 'będzie', 'bo', 'bowiem', 'by', 'byc', 'być', 'byl', 'byla', 'byli', 'bylo', 'byly', 'był', 'była', 'było', 'były', 'bynajmniej', 'cala', 'cali', 'caly', 'cała', 'cały', 'ci', 'cie', 'ciebie', 'cię', 'co', 'cokolwiek', 'cos', 'coś', 'czasami', 'czasem', 'czemu', 'czy', 'czyli', 'daleko', 'dla', 'dlaczego', 'dlatego', 'do', 'dobrze', 'dokad', 'dokąd', 'dosc', 'dość', 'duzo', 'dużo', 'dwa', 'dwaj', 'dwie', 'dwoje', 'dzis', 'dzisiaj', 'dziś', 'gdy', 'gdyby', 'gdyz', 'gdyż', 'gdzie', 'gdziekolwiek', 'gdzies', 'gdzieś', 'go', 'i', 'ich', 'ile', 'im', 'inna', 'inne', 'inny', 'innych', 'iz', 'iż', 'ja', 'jak', 'jakas', 'jakaś', 'jakby', 'jaki', 'jakichs', 'jakichś', 'jakie', 'jakis', 'jakiś', 'jakiz', 'jakiż', 'jakkolwiek', 'jako', 'jakos', 'jakoś', 'ją', 'je', 'jeden', 'jedna', 'jednak', 'jednakze', 'jednakże', 'jedno', 'jego', 'jej', 'jemu', 'jesli', 'jest', 'jestem', 'jeszcze', 'jeśli', 'jezeli', 'jeżeli', 'juz', 'już', 'kazdy', 'każdy', 'kiedy', 'kilka', 'kims', 'kimś', 'kto', 'ktokolwiek', 'ktora', 'ktore', 'ktorego', 'ktorej', 'ktory', 'ktorych', 'ktorym', 'ktorzy', 'ktos', 'ktoś', 'która', 'które', 'którego', 'której', 'który', 'których', 'którym', 'którzy', 'ku', 'lat', 'lecz', 'lub', 'ma', 'mają', 'mało', 'mam', 'mi', 'miedzy', 'między', 'mimo', 'mna', 'mną', 'mnie', 'moga', 'mogą', 'moi', 'moim', 'moj', 'moja', 'moje', 'moze', 'mozliwe', 'mozna', 'może', 'możliwe', 'można', 'mój', 'mu', 'musi', 'my', 'na', 'nad', 'nam', 'nami', 'nas', 'nasi', 'nasz', 'nasza', 'nasze', 'naszego', 'naszych', 'natomiast', 'natychmiast', 'nawet', 'nia', 'nią', 'nic', 'nich', 'nie', 'niech', 'niego', 'niej', 'niemu', 'nigdy', 'nim', 'nimi', 'niz', 'niż', 'no', 'o', 'obok', 'od', 'około', 'on', 'ona', 'one', 'oni', 'ono', 'oraz', 'oto', 'owszem', 'pan', 'pana', 'pani', 'po', 'pod', 'podczas', 'pomimo', 'ponad', 'poniewaz', 'ponieważ', 'powinien', 'powinna', 'powinni', 'powinno', 'poza', 'prawie', 'przeciez', 'przecież', 'przed', 'przede', 'przedtem', 'przez', 'przy', 'roku', 'rowniez', 'również', 'sam', 'sama', 'są', 'sie', 'się', 'skad', 'skąd', 'soba', 'sobą', 'sobie', 'sposob', 'sposób', 'swoje', 'ta', 'tak', 'taka', 'taki', 'takie', 'takze', 'także', 'tam', 'te', 'tego', 'tej', 'ten', 'teraz', 'też', 'to', 'toba', 'tobą', 'tobie', 'totez', 'toteż', 'totobą', 'trzeba', 'tu', 'tutaj', 'twoi', 'twoim', 'twoj', 'twoja', 'twoje', 'twój', 'twym', 'ty', 'tych', 'tylko', 'tym', 'u', 'w', 'wam', 'wami', 'was', 'wasz', 'wasza', 'wasze', 'we', 'według', 'wiele', 'wielu', 'więc', 'więcej', 'wlasnie', 'właśnie', 'wszyscy', 'wszystkich', 'wszystkie', 'wszystkim', 'wszystko', 'wtedy', 'wy', 'z', 'za', 'zaden', 'zadna', 'zadne', 'zadnych', 'zapewne', 'zawsze', 'ze', 'zeby', 'zeznowu', 'zł', 'znow', 'znowu', 'znów', 'zostal', 'został', 'żaden', 'żadna', 'żadne', 'żadnych', 'że', 'żeby']\n",
    "\n",
    "    def __findBooksPaths(self) -> list:\n",
    "        result = []\n",
    "        for root, dirs, files in os.walk(self.__booksRelPath):\n",
    "            for name in files:\n",
    "                if fnmatch.fnmatch(name, '*_*.txt'):\n",
    "                    result.append(os.path.join(root, name))\n",
    "        return result\n",
    "\n",
    "    def __retrieveTokensFromBook(self, path) -> None:\n",
    "        usidx = path.index('_', len(self.__booksRelPath)+1)\n",
    "        author = path[len(self.__booksRelPath)+1:usidx]\n",
    "\n",
    "        self.__authorsWB[author] = self.__authorsWB.get(author, dict())\n",
    "        tokens_stop = []\n",
    "        tokens = []\n",
    "\n",
    "        with open(path, 'r', encoding='utf-8') as book:\n",
    "            for line in book:        \n",
    "                for char in self.__unnecessary_chars:\n",
    "                    line = line.replace(char, '')\n",
    "                line = line.rstrip().lower().split()\n",
    "\n",
    "                if line:\n",
    "                    tokens_stop.extend(line)\n",
    "\n",
    "        for ts in tokens_stop:\n",
    "            if not ts in self.__stops:\n",
    "                tokens.append(ts)\n",
    "\n",
    "        for word in sorted(tokens):\n",
    "            if word.isalpha():\n",
    "                self.__authorsWB[author][word] = self.__authorsWB[author].get(word, 0) + 1\n",
    "\n",
    "    def __truncateAuthorsWB(self) -> None:\n",
    "        for author in self.__authorsWB:\n",
    "            tempWB = dict(sorted(self.__authorsWB[author].items(), key=lambda x: x[1], reverse = True))\n",
    "            self.__authorsWB[author] = dict()\n",
    "\n",
    "            count = min(len(tempWB.keys()), self.__lim)\n",
    "            for token in tempWB:\n",
    "                self.__authorsWB[author][token] = tempWB[token]\n",
    "\n",
    "                if count < 0: break\n",
    "                count -= 1\n",
    "                \n",
    "    def __buildAuthorsWB(self) -> None:\n",
    "        paths = self.__findBooksPaths()\n",
    "        for p in paths:\n",
    "            self.__retrieveTokensFromBook(p)\n",
    "        self.__truncateAuthorsWB()\n",
    "\n",
    "    def __buildTokenSet(self, frag) -> list:\n",
    "        '''\n",
    "        Builds token set for specified text.\n",
    "        @params:\n",
    "            frag     - Required : literary work fragment for analysis (Str)\n",
    "        '''\n",
    "        frag = frag.replace('\\n', ' ')\n",
    "        for char in self.__unnecessary_chars:\n",
    "            frag = frag.replace(char, '')\n",
    "        frag = frag.strip().lower().split()\n",
    "\n",
    "        tokens = []\n",
    "        for token in frag:\n",
    "            if token not in tokens and token not in self.__stops:\n",
    "                tokens.append(token)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def __buildClassifier(self) -> None:\n",
    "        self.__authorTotal = dict([(a, 0) for a in self.__authorsWB])\n",
    "        self.__authorScore = dict([(a, 0) for a in self.__authorsWB])\n",
    "\n",
    "        for author in self.__authorsWB:\n",
    "            for token in self.__authorsWB[author]:\n",
    "                self.__authorTotal[author] += self.__authorsWB[author][token]\n",
    "\n",
    "    def __clearScore(self) -> None:\n",
    "        for author in self.__authorsWB:\n",
    "            self.__authorScore[author] = 0\n",
    "\n",
    "    def __prepareClassification(self, frag) -> None:\n",
    "        self.__clearScore()\n",
    "        fragtokens = self.__buildTokenSet(frag)\n",
    "\n",
    "        for author in self.__authorsWB:\n",
    "            for token in fragtokens:\n",
    "                self.__authorScore[author] += self.__authorsWB[author].get(token, 0)\n",
    "\n",
    "    def classifyFullProb(self, frag) -> dict:\n",
    "        self.__prepareClassification(frag)\n",
    "        result = dict()\n",
    "        for author in self.__authorScore:\n",
    "            result[author] = self.__authorScore[author] / self.__authorTotal[author] * 100\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def classify(self, frag) -> str:\n",
    "        full = self.classifyFullProb(frag)\n",
    "        maxa = \"\"\n",
    "        maxi = 0\n",
    "        for author in self.__authorsWB:\n",
    "            if full[author] > maxi:\n",
    "                maxi = full[author]\n",
    "                maxa = author\n",
    "        return maxa\n",
    "\n",
    "    def getAuthors(self) -> list:\n",
    "        return list(self.__authorsWB.keys())\n",
    "    \n",
    "    def getAuthWB(self):\n",
    "        return self.__authorsWB\n",
    "\n",
    "    def __init__(self, booksRelPath, lim) -> None:\n",
    "        self.__booksRelPath = booksRelPath\n",
    "        self.__lim = lim\n",
    "        self.__authorsWB = dict()\n",
    "\n",
    "        self.__buildAuthorsWB()\n",
    "        self.__buildClassifier()\n",
    "\n",
    "# WordBagOfAuthorClassifier - do zadanego fragmentu autor jest dopasowywany na podstawie tylko najczestszych tokenow z calej puli dziel \n",
    "# ewaluacja - wynik dopasowania = suma wystapien trafionych tokenow we fragmencie / suma wystapien wszystkich tokenow autora - wybierany jest autor o najwiekszej nocie \n",
    "# natomiast moze lepiej byloby dac cos logarytmicznego wzgledem ilosci wszystkich tokenow??\n",
    "\n",
    "# pola:\n",
    "# __booksRelPath (str)  - sciezka do zbioru wszystkich ksiazek wszystkich autorow                               - na nich kompilowany jest klasyfikator\n",
    "# __lim (int)           - liczba najczestszych tokenow dla kazdego autora\n",
    "# __authorsWB (dict)    - mapa <author_slug : worek_slow>, gdzie worek_slow to mapa <token : ilosc_wystapien>   - zawiera najczestsze tokeny ze wszystkich dziel dla wszystkich autorow\n",
    "# __authorTotal (dict)  - mapa <author_slug : laczna_ilosc_wystapien_wszystkich_tokenow>                        - potrzebne do ewaluacji \n",
    "# __authorScore (dict)  - mapa <author_slug : suma_wystapien_tokenow_autora_we_fragmencie>                      - potrzebne do ewaluacji\n",
    "\n",
    "# metody publiczne:\n",
    "# getAuthors() -> list              - zwraca liste wszytkich kategorii (autorow) skompilowanego klasyfikatora\n",
    "# classify(frag) -> str             - zwraca autora dopasowanego do fragmentu utworu\n",
    "# classifyFullProb(frag) -> dict    - zwraca mape <author_slug : wynik_dopasowania> czyli wyniki dopasowania do fragmentu dla wszystkich autorow, przydatne raczej do debugu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486ddf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rzekł': 160, 'hrabia': 136, 'ksiądz': 132, 'sędzia': 127, 'potem': 118, 'choć': 111, 'panie': 107, 'tadeusz': 107, 'oczy': 106, 'senator': 106, 'domu': 100, 'cóż': 99, 'miał': 94, 'raz': 92, 'wojski': 89, 'ziemi': 80, 'ręce': 76, 'bóg': 75, 'siebie': 74, 'ks': 72, 'razem': 67, 'głowę': 64, 'mię': 64, 'szlachta': 64, 'dzieci': 63, 'piotr': 63, 'głowy': 62, 'długo': 61, 'rękę': 61, 'tyle': 61, 'ledwie': 60, 'gerwazy': 60, 'rzecz': 58, 'strony': 57, 'patrz': 56, 'ręką': 56, 'serce': 56, 'telimena': 56, 'dotąd': 55, 'widać': 55, 'głos': 54, 'pierwszy': 54, 'wiem': 54, 'pustelnik': 54, 'tadeusza': 54, 'nikt': 53, 'wielki': 53, 'wtem': 53, 'zaraz': 53, 'czas': 52, 'drzwi': 52, 'ni': 52}\n"
     ]
    }
   ],
   "source": [
    "K = WordBagOfAuthorClassifier('..\\\\books', 50)\n",
    "\n",
    "awb = K.getAuthWB()\n",
    "print(awb['adam-mickiewicz'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
